profile: https://medium.com/@SaschaKirch
subscription_page: https://medium.com/@SaschaKirch/subscribe
friend_links:
  - title: Splat Your Own Gaussians - From Circles to Ellipses
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: Part 3 of Building a 3D Gaussian Splatting Renderer â€” Covariance Matrices, Jacobians, and Proper 2D Projection
    link: https://medium.com/ai-advances/splat-your-own-gaussians-from-circles-to-ellipses-96b69f1e7e3f?sk=cc15df35d8dfbb381eae69a1f44db4f7
  - title: Circles Are Not Gaussians (But Letâ€™s Pretend They Are)
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: Part 2 of Building a 3D Gaussian Splatting Renderer - Circles, Colors, and Transparency
    link: https://medium.com/ai-advances/circles-are-not-gaussians-but-lets-pretend-they-are-7bcf6db6efb8?sk=a4a27e16d71f4c1742b8ec6f45550673
  - title: I Built the Slowest 3D Gaussian Splatting Rendererâ€¦ On Purpose
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: Building a deliberately slow, crystal-clear Python renderer to reveal the implementation details that papers skip and GPU kernels hide
    link: https://medium.com/ai-advances/i-built-the-slowest-3d-gaussian-splatting-renderer-on-purpose-a8170b90d9b4?sk=0a2c1a32a01f0cfb3c9050f7c045483f
  - title: Still Avoiding einsum()? Itâ€™s Time to Fix That
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: Build Intuition, Master the Syntax, and Apply einsum() with Real Examples and a Handy Cheat Sheet
    link: https://medium.com/ai-advances/still-avoiding-einsum-its-time-to-fix-that-6779be94c7ed?sk=85e76dc04bf57067d757421f5f38f06c
  - title: Mastering NumPy - Manual Metadata Manipulation for Memory-Efficient Arrays
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: Part 3 - NumPy Like a Pro - A Deep Dive Into Arrays and Performance
    link: https://medium.com/ai-advances/mastering-numpy-manual-metadata-manipulation-for-memory-efficient-arrays-fc461f64074f?sk=042e5d224a909135a57f417637758ec2
  - title: The Power of Views - How NumPy Avoids Copies and Saves Memory
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: Part 2 - NumPy Like a Pro - A Deep Dive Into Arrays and Performance
    link: https://medium.com/ai-advances/the-power-of-views-how-numpy-avoids-copies-and-saves-memory-4421bea71dd2?sk=16bb56b69ac6a42806f3d84ae189f336
  - title: Why NumPy Arrays Are So Fast (And How They Really Work)
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: Part 1 - NumPy Like a Pro - A Deep Dive Into Arrays and Performance
    link: https://medium.com/ai-advances/why-numpy-arrays-are-so-fast-and-how-they-really-work-1e5b56c75f8b?sk=52197f4924d47e3dba4dc4d6c0cea360
  - title: FlashAttention â€” Visually and Exhaustively Explained
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Part 2 - FlashAttention from First Principles
    link: https://medium.com/ai-advances/flashattention-visually-and-exhaustively-explained-d6124670f7fb?sk=a695dae681cadef47624378aae004a83
  - title: FlashAttention from First Principles
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Part 1 - All the Basics you need!
    link: https://medium.com/ai-advances/flashattention-from-first-principles-part-1-5a9f2407d739?sk=ba068449f89ce8a6a2582b4e5a9b25ec
  - title: Vision Mamba - Like a Vision Transformer but Better
    kicker: ğŸ Towards Mamba State Space Models for Images, Videos and Time Series
    subtitle: Part 4 - Towards Mamba State Space Models for Images, Videos and Time Series
    link: https://medium.com/towards-data-science/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?sk=2a84edececf20d69284ea5b03c058fa9
  - title: Here Comes Mamba - The Selective State Space Model
    kicker: ğŸ Towards Mamba State Space Models for Images, Videos and Time Series
    subtitle: Part 3 - Towards Mamba State Space Models for Images, Videos and Time Series
    link: https://medium.com/towards-data-science/here-comes-mamba-the-selective-state-space-model-435e5d17a451?sk=602b692eda48c19b2b2f4b0a7198bbcb
  - title: Structured State Space Models Visually Explained
    kicker: ğŸ Towards Mamba State Space Models for Images, Videos and Time Series
    subtitle: Part 2 - Towards Mamba State Space Models for Images, Videos and Time Series
    link: https://medium.com/towards-data-science/structured-state-space-models-visually-explained-86cfe2757386?sk=479768bd75ecf8d410f902b7ad8c0836
  - title: Towards Mamba State Space Models for Images, Videos and Time Series
    kicker: ğŸ Towards Mamba State Space Models for Images, Videos and Time Series
    subtitle: Part 1
    link: https://medium.com/towards-data-science/towards-mamba-state-space-models-for-images-videos-and-time-series-1e0bfdb5933a?sk=8aaecd0fc979e1e95ac2a8e62946064b
  - title: The Rise of Diffusion Models - A new Era of Generative Deep Learning
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Denoising Diffusion Probabilistic Models by J. Ho et. al.
    link: https://medium.com/towards-data-science/the-rise-of-diffusion-models-a-new-era-of-generative-deep-learning-3ef4779f6e1b?sk=8c178422a977c6f49ec24b13502be4fd
  - title: Depth Anything - A Foundation Model for Monocular Depth Estimation
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Depth Anything, Unleashing the Power of Large-Scale Unlabeled Data by L. Yang et. al.
    link: https://medium.com/towards-data-science/depth-anything-a-foundation-model-for-monocular-depth-estimation-8a7920b5c9cc?sk=fc6197edd68e6137c3396c83e50f65cb
  - title: Turn Yourself into a 3D Gaussian Splat
    kicker: false
    subtitle: A Hands-on Guide for Practitioners
    link: https://medium.com/towards-data-science/turn-yourself-into-a-3d-gaussian-splat-3a2bc59a770f?sk=b6960d4195bb96994f1af119677e654e
  - title: DINO - A Foundation Model for Computer Vision
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Emerging Properties in Self-Supervised Vision Transformers by M. Caron et. al.
    link: https://medium.com/towards-data-science/dino-a-foundation-model-for-computer-vision-4cb08e821b18?sk=d85260276367f5914cc3efadc0fe307c
  - title: Segment Anything - Promptable Segmentation of Arbitrary Objects
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Segment Anything by A. Krillov et. al.
    link: https://medium.com/towards-data-science/segment-anything-promptable-segmentation-of-arbitrary-objects-f28958c5612d?sk=bd1311a6d8b1e0e6d3369d536dba0700
  - title: BYOL -The Alternative to Contrastive Self-Supervised Learning
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Bootstrap Your Own Latent, A New Approach to Self-Supervised Learning by J. Grill et. al.
    link: https://medium.com/towards-data-science/byol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c?sk=fc5a3b3a556088181d8726226862252c
  - title: GLIP - Introducing Language-Image Pre-Training to Object Detection
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Grounded Language-Image Pre-training by L. H. Li et. al.
    link: https://medium.com/towards-data-science/glip-introducing-language-image-pre-training-to-object-detection-5ddb601873aa?sk=4f0acb404a38d342b7669f861c013a05
  - title: The CLIP Foundation Model
    kicker: ğŸš€ Sascha's Paper Club
    subtitle: Learning Transferable Visual Models From Natural Language Supervision by A. Radford et. al.
    link: https://medium.com/towards-data-science/the-clip-foundation-model-7770858b487d?sk=a7b10ba1d0c3a20ecd4adb8200a48500
  - title: Implement Multi-GPU Training on a single GPU
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: An Advanced Guide for TensorFlow
    link: https://medium.com/towards-data-science/implement-multi-gpu-training-on-a-single-gpu-e9b6b775456a?sk=33a6f419491784d491da7e4e2f9149a0
  - title: Fourier CNNs with Kernel Sizes of 1024x1024 and Larger
    kicker: false
    subtitle: Multi-Dimensional Fourier Transformations in Convolutional Neural Networks
    link: https://medium.com/towards-data-science/fourier-cnns-with-kernel-sizes-of-1024x1024-and-larger-29f513fd6120?sk=e2c41277d25c98d08214778eff603d2a
  - title: MLP Mixer in a Nutshell
    kicker: false
    subtitle: A Resource-Saving and Performance-Competitive Alternative to Vision Transformers
    link: https://medium.com/towards-data-science/mlp-mixer-in-a-nutshell-eccffb68e4fc?sk=09000a6a1a857367707f7b8d6c29dabc
  - title: Create your own GPU accelerated Jupyter Notebook Server with Google Colab using Docker
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: A Step-by-Step Guide
    link: https://medium.com/towards-data-science/create-your-own-gpu-accelerated-yupyter-notebook-server-with-google-colab-using-docker-2fa14900bab5?sk=669c6d11f486cdc104fdb0df4b9da6f4
  - title: Accelerated Distributed Training with TensorFlow on Google's TPU
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: Understanding the Hardware to Optimize the Software!
    link: https://medium.com/towards-data-science/accelerated-distributed-training-with-tensorflow-on-googles-tpu-52f1fe21da33?sk=b713cd3cf705bae60c523b26cfe25b3f
  - title: Speed up your Training with Mixed Precision on GPUs and TPUs in TensorFlow
    kicker: ğŸ’» Code & Coffee with Sascha â˜•
    subtitle: A simple step-by-step Guide
    link: https://medium.com/towards-data-science/speed-up-your-tensorflow-training-with-mixed-precision-on-gpu-tpu-acf4c8c0931c?sk=ff0bc89c30ef29eb924c3a096bba62c4
