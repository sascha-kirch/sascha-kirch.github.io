---
title: Multi-Sensor 360Â° Data Collection and Ground Truth Generation for Autonomous Driving
order: 10
image: gt.png
---

why we even need data, why we need high-quality ground truth for autonomous driving, but what else can we do with such data...
why automated ground truth is important... 
why a hybrid approach with deep learning, classical computer vision and especially domain knowledge is important and prefered over end-to-end deep learning only approaches...
its not only about labeling data for supervised training, but also record diverse multi-sensor data for validation, testing and simulation and unsupervised training. 
sensor fusion of different modalities, offline processing mitigates causality and realtime constraints, calibration, time synchronization, are crucial...
endlessly many challenges but also opportunities and possibilities... sadly i can't share too many specifics about the actual implementation...

Full-Stack development of a deep learning-based ground truth system for autonomous driving featuring multiple cameras,  LiDARs, radars, GPS, and inertial sensors. my team is responsible for the entire pipeline from sensor selection and positioning, data collection and storage, sensor calibration, time synchronization, data processing, annotation, and quality assurance to final data packaging for training and validation.
why it is not easy to handle so much data during capturing and also processing.

It combines deep learning, machinelearning, classical computer vision algorithms, and foundation models to ensure highperformance within a high range.
